# coding=utf-8
"""
DATE:   2021/10/26
AUTHOR: TesterCC
"""
import os
from collections import namedtuple
import csv
import time

exclude_cwes = ['CWE-306',
 'CWE-269',
 'CWE-77',
 'CWE-787',
 'CWE-476',
 'CWE-287',
 'CWE-78',
 'CWE-640',
 'CWE-93',
 'CWE-338',
 'CWE-434',
 'CWE-190',
 'CWE-362',
 'CWE-863',
 'CWE-22',
 'CWE-89',
 'CWE-917',
 'CWE-284',
 'CWE-79',
 'CWE-358',
 'CWE-74',
 'CWE-502',
 'CWE-352',
 'CWE-19',
 'CWE-20',
 'CWE-119',
 'CWE-611',
 'CWE-693',
 'CWE-94',
 'CWE-416',
 'CWE-1188'
 'CWE-918',
 'CWE-120',
 'CWE-601',
 'CWE-88',
 'CWE-862',
 'CWE-200',
 'CWE-264',
 'CWE-276']


# step 1 : read_csv, get exploit-db id
exploit_db_py = list()
# UnicodeDecodeError: 'gbk' codec can't decode byte 0x80 in position  -- add encoding
# with open('files_exploits.csv',encoding='UTF-8') as f:
with open('files_all.csv',encoding='UTF-8') as f:
    f_csv = csv.reader(f)
    headings =  next(f_csv)
    # ['id', 'file', 'description', 'date', 'author', 'type', 'platform', 'port']
    # print(headings)
    Row = namedtuple('Row', headings)
    for r in f_csv:
        row = Row(*r)
        # Process row
        # print(row)
        # print(os.path.basename(row.file))
        file_name = os.path.basename(row.file)
        if ".py" in file_name:
            # print(row.id)
            exploit_db_py.append(row.id)


output_list = list(set(exploit_db_py))
len(output_list)
print("Total python poc count: ", len(output_list))   # 3809
print(output_list)  # debug
print("*" * 77)

# step 2 : visit and get cve-no
# https://www.exploit-db.com/exploits/14727
# 根据这个抓取CVE编号
# xpath 手工定位 //h6[@class='stats-title']/a[contains(@href,'vuln/detail')]/text()
# 写文件，不然要疯狂

import requests
from bs4 import BeautifulSoup


# todo 此处可将请求封装一下
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',
           'Accept': '*/*',
           'Accept-Language': 'en-US,en;q=0.5',
           'Accept-Encoding': 'gzip,deflate',
           'referer': "https://www.exploit-db.com/"}

# custom 不限速可能会被封
for eid in output_list:
    url = f"https://www.exploit-db.com/exploits/{eid}"
    print("url: ", url)
    conn = requests.session()
    conn.get(url, headers=headers)
    html = conn.get(url, stream=True, headers=headers, timeout=10)
    time.sleep(0.7)
    soup = BeautifulSoup(html.content, 'html.parser')

    # print(soup.prettify())   # 格式化请求到的页面
    # print("="*77)
    for div in soup.find_all('div', class_='col-sm-12 col-md-6 col-lg-3 d-flex align-items-stretch'):
        # 正常的输出逻辑
        for h in div.find_all('div', class_='col-6 text-center'):
            if "CVE" in h.h4.get_text().strip():
                if h.h6.get_text().strip():
                    if h.h6.get_text().strip() != "N/A":
                        cve_list = [i for i in h.h6.get_text().strip().replace("\n","").split(" ") if i]
                        if cve_list:
                            print("CVE_NO:", cve_list)   # 处理为这样 ['2014-0346', '2014-0160']
                        else:
                            print("CVE_NO:", "N/A")
            else:
                print(h.h4.get_text().strip() + h.h6.get_text().strip())

        for s in div.find_all('div', class_='stats h5 text-center'):
            if s.strong.string.strip() == 'EDB Verified:':
                if s.i['class'] == ['mdi', 'mdi-24px', 'mdi-check']:
                    print('EDB Verified: Yes')
                else:
                    print('EDB Verified: No')
            elif s.strong.string.strip() == 'Exploit:':
                print(s.strong.string.strip() + s.a['href'])
            else:
                if s.find('a') is None:
                    print(s.strong.string.strip())
                else:
                    print(s.strong.string.strip() + s.a['href'])
    print("-"*77)

# step 3 : visit and get cve's cwe


# step 4 : according to exclude_cwes get other cwes